{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The goal of this project is to create an ETL pipeline for creating a database from four different datsets. Ultimately, we'll use the database to analyze immigration related scenarios.  \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from pyspark.sql import SparkSession,SQLContext, GroupedData\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StructType\n",
    "from us_state_abbrev import state_udf, abbrev_state, abbrev_state_udf,city_code_udf,city_codes \n",
    "from immigration_codes import country_udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spack session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fd3df0119d82:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fae5c6c88d0>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build SQL context object\n",
    "sqlContext = SQLContext(spark)\n",
    "\n",
    "# Check Spark information\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "We'll pull data from four different sources as below to create fact and dimension tables. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "-   **U.S. City Demographic Data**: Comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/).        \n",
    "\n",
    "> Dataframe information  (2891 records)  \n",
    "    \n",
    "    City                       object  \n",
    "    State                      object\n",
    "    Median Age                float64\n",
    "    Male Population           float64\n",
    "    Female Population         float64\n",
    "    Total Population            int64\n",
    "    Number of Veterans        float64\n",
    "    Foreign-born              float64\n",
    "    Average Household Size    float64\n",
    "    State Code                 object\n",
    "    Race                       object\n",
    "    Count                       int64\n",
    "\n",
    "    \n",
    "-   **Airport Code Table**: Comes from [DataHub.io](https://datahub.io/core/airport-codes#data).        \n",
    "\n",
    "> Dataframe information    (55075  records)\n",
    "\n",
    "    ident            object  \n",
    "    type             object  \n",
    "    name             object  \n",
    "    elevation_ft    float64  \n",
    "    continent        object  \n",
    "    iso_country      object  \n",
    "    iso_region       object  \n",
    "    municipality     object  \n",
    "    gps_code         object  \n",
    "    iata_code        object  \n",
    "    local_code       object  \n",
    "    coordinates      object  \n",
    "\n",
    "\n",
    "-   **World Temperature Data**: Comes from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data).        \n",
    "\n",
    "> Raw Data Information  (645675 records)   \n",
    "\n",
    "    dt                                object  \n",
    "    AverageTemperature               float64  \n",
    "    AverageTemperatureUncertainty    float64  \n",
    "    State                             object  \n",
    "    Country                           object  \n",
    "    \n",
    " -   **Immigration I94 Data**: Comes from [the US National Tourism and Trade Offic](https://travel.trade.gov/research/reports/i94/historical/2016.html).        \n",
    "\n",
    "> Raw Data Information     \n",
    "    ```\n",
    "    cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here (The first three CSV data)\n",
    "demographic=pd.read_csv(\"us-cities-demographics.csv\", sep =';')\n",
    "airport= pd.read_csv(\"airport-codes_csv.csv\",sep =',')\n",
    "temperatures =pd.read_csv(\"GlobalLandTemperaturesByState.csv\",sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: demographic\n",
      " *************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2891 entries, 0 to 2890\n",
      "Data columns (total 12 columns):\n",
      "City                      2891 non-null object\n",
      "State                     2891 non-null object\n",
      "Median Age                2891 non-null float64\n",
      "Male Population           2888 non-null float64\n",
      "Female Population         2888 non-null float64\n",
      "Total Population          2891 non-null int64\n",
      "Number of Veterans        2878 non-null float64\n",
      "Foreign-born              2878 non-null float64\n",
      "Average Household Size    2875 non-null float64\n",
      "State Code                2891 non-null object\n",
      "Race                      2891 non-null object\n",
      "Count                     2891 non-null int64\n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 271.1+ KB\n",
      "None\n",
      "Dataset: airport\n",
      " *************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      "ident           55075 non-null object\n",
      "type            55075 non-null object\n",
      "name            55075 non-null object\n",
      "elevation_ft    48069 non-null float64\n",
      "continent       27356 non-null object\n",
      "iso_country     54828 non-null object\n",
      "iso_region      55075 non-null object\n",
      "municipality    49399 non-null object\n",
      "gps_code        41030 non-null object\n",
      "iata_code       9189 non-null object\n",
      "local_code      28686 non-null object\n",
      "coordinates     55075 non-null object\n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n",
      "None\n",
      "Dataset: temperatue\n",
      " *************\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 645675 entries, 0 to 645674\n",
      "Data columns (total 5 columns):\n",
      "dt                               645675 non-null object\n",
      "AverageTemperature               620027 non-null float64\n",
      "AverageTemperatureUncertainty    620027 non-null float64\n",
      "State                            645675 non-null object\n",
      "Country                          645675 non-null object\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 24.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get basic informatin of the dataset\n",
    "print('Dataset: demographic\\n', '*************')\n",
    "print(demographic.info())\n",
    "print('Dataset: airport\\n', '*************')\n",
    "print(airport.info())\n",
    "print('Dataset: temperatue\\n', '*************')\n",
    "print(temperatures.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark=spark.read.format('com.github.saurfang.sas.spark').load(\"../../data/18-83510-I94-Data-2016/i94_jun16_sub.sas7bdat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-----------+-----------+----------+-----------+-------------+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|validres|delete_days|delete_mexl|delete_dup|delete_visa|delete_recdup|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|         admnum|fltno|visatype|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-----------+-----------+----------+-----------+-------------+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|  4.0|2016.0|   6.0| 135.0| 135.0|    XXX|20612.0|   null|   null|   null|  59.0|    2.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      Z|   null|      U|   null| 1957.0|10032016|  null|  null|   null|1.4938462027E10| null|      WT|\n",
      "|  5.0|2016.0|   6.0| 135.0| 135.0|    XXX|20612.0|   null|   null|   null|  50.0|    2.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      Z|   null|      U|   null| 1966.0|10032016|  null|  null|   null|1.7460063727E10| null|      WT|\n",
      "|  6.0|2016.0|   6.0| 213.0| 213.0|    XXX|20609.0|   null|   null|   null|  27.0|    3.0|  1.0|     1.0|        0.0|        0.0|       0.0|        0.0|          0.0|    null|    null| null|      T|   null|      U|   null| 1989.0|     D/S|  null|  null|   null|  1.679297785E9| null|      F1|\n",
      "+-----+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+-----------+-----------+----------+-----------+-------------+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "The goal of this section is to identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "**1 ) Immigration Data:**  \n",
    "     <li>  get country_name, visatype, port(city/state) information from I94_SAS_Labels_Descriptions.SAS\n",
    "     <li>  remove nulls based on i94addr and i94res col \n",
    "     <li>  convert the i94yr to date type \n",
    "     <li>  select only needed columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def process_sas_file_spark_dataframe(section, col):\n",
    "    \"\"\"\n",
    "    Process Sas file to retrieve counrty, port and address data -> To spark dataframe\n",
    "    \"\"\"\n",
    "    with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "        file_string = f.read()\n",
    "        f_read = file_string[file_string.index(section):].split(';')[0].split('\\n')\n",
    "    records= [ ]\n",
    "    for row in f_read:\n",
    "        if '=' in row:\n",
    "            code, val = row.split('=')[0], row.split('=')[1]\n",
    "            code = code.strip()\n",
    "            val = val.strip()\n",
    "            if code[0] ==\"'\":\n",
    "                records.append([code[1:-1],val[1:-1]])\n",
    "            else:\n",
    "                records.append([code,val[1:-1]])\n",
    "    end_frame = sqlContext.createDataFrame(records, col)\n",
    "    return end_frame\n",
    "\n",
    "def process_sas_file_pandas_dataframe(section, col):\n",
    "    \"\"\"\n",
    "    Process Sas file to retrieve counrty, port and address data -> To pandas dataframe \n",
    "    \"\"\"\n",
    "    with open('I94_SAS_Labels_Descriptions.SAS') as f:\n",
    "        file_string = f.read()\n",
    "        f_read = file_string[file_string.index(section):].split(';')[0].split('\\n')\n",
    "    records= [ ]\n",
    "    for row in f_read:\n",
    "        if '=' in row:\n",
    "            code, val = row.split('=')[0], row.split('=')[1]\n",
    "            code = code.strip()\n",
    "            val = val.strip()\n",
    "            if code[0] ==\"'\":\n",
    "                records.append([code[1:-1],val[1:-1]])\n",
    "            else:\n",
    "                records.append([code,val[1:-1]])\n",
    "    end_frame = pd.DataFrame(records, columns=col)\n",
    "    return end_frame\n",
    "\n",
    "# Create Spark dataframe from the above function\n",
    "i94cntyl = process_sas_file_spark_dataframe('i94cntyl',  ('code', 'country'))\n",
    "i94port  = process_sas_file_spark_dataframe('i94prtl',  ('code', 'port'))\n",
    "i94addr= process_sas_file_spark_dataframe('i94addrl', ('code', 'addr'))\n",
    "\n",
    "# Create pandas dataframe for later use (get abbreviation for Temperature data)\n",
    "i94addr_reference= process_sas_file_pandas_dataframe('i94addrl', ['code', 'addr'])\n",
    "i94cntyl_reference = process_sas_file_pandas_dataframe('i94cntyl',  ['code', 'country'])\n",
    "i94port_reference  = process_sas_file_pandas_dataframe('i94prtl',  ['code', 'port'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark_sub =df_spark.filter(df_spark.i94addr.isNotNull())\\\n",
    "                .filter(df_spark.i94res.isNotNull())\\\n",
    "                .filter(df_spark.i94addr.isin(list(abbrev_state.keys())))\\\n",
    "                .filter(df_spark.i94port.isin(list(city_codes.keys())))\\\n",
    "                .withColumn(\"origin_country\",country_udf(df_spark[\"i94res\"]))\\\n",
    "                .withColumn(\"dest_state_name\",abbrev_state_udf(df_spark[\"i94addr\"]))\\\n",
    "                .withColumn(\"i94yr\", df_spark.i94yr.cast(\"integer\"))\\\n",
    "                .withColumn(\"i94mon\",df_spark.i94mon.cast(\"integer\"))\\\n",
    "                .withColumn(\"city_port_name\",city_code_udf(df_spark[\"i94port\"]))\n",
    "\n",
    "immigration_df  =df_spark_sub.select(\"cicid\",df_spark_sub.i94yr.alias(\"year\"),df_spark_sub.i94mon.alias(\"month\"),\\\n",
    "                             \"origin_country\",\"i94port\",\"city_port_name\",df_spark_sub.i94addr.alias(\"state_code\"),\"dest_state_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+--------------+-------+------------------+----------+---------------+\n",
      "|cicid|year|month|origin_country|i94port|    city_port_name|state_code|dest_state_name|\n",
      "+-----+----+-----+--------------+-------+------------------+----------+---------------+\n",
      "| 41.0|2016|    6|   SOUTH KOREA|    SFR|SAN FRANCISCO     |        CA|     California|\n",
      "| 42.0|2016|    6|   SOUTH KOREA|    SFR|SAN FRANCISCO     |        CA|     California|\n",
      "| 45.0|2016|    6|       ROMANIA|    HOU|HOUSTON           |        TX|          Texas|\n",
      "| 52.0|2016|    6|       ALBANIA|    BOS|BOSTON            |        MA|  Massachusetts|\n",
      "| 53.0|2016|    6|       ALBANIA|    NEW|NEWARK/TETERBORO  |        PA|   Pennsylvania|\n",
      "+-----+----+-----+--------------+-------+------------------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_df.show(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**2 ) US Demographic Data:**  \n",
    "     <li>  retrieve the columns needed \n",
    "     <li>  calculate the percentage of foreign born person out of total population \n",
    "     <li>  convert the male and female population in percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographic_df = demographic.loc[:,['Male Population', 'Female Population',\n",
    "       'Total Population',  'Foreign-born',\n",
    "       'State Code']]\n",
    "demographic_df['pct_male'] = demographic_df['Male Population']/demographic_df['Total Population']\n",
    "demographic_df['pct_female'] = demographic_df['Female Population']/demographic_df['Total Population']\n",
    "demographic_df['pct_foreign'] = demographic_df['Foreign-born']/demographic_df['Total Population']\n",
    "demographic_df = demographic_df.loc[:,['pct_male','pct_foreign','pct_female','State Code','Total Population'] ]\n",
    "demographic_df['pct_male'] = demographic_df['pct_male'].round(decimals=2)\n",
    "demographic_df['pct_female'] = demographic_df['pct_female'].round(decimals=2)\n",
    "demographic_df['pct_foreign'] = demographic_df['pct_foreign'].round(decimals=2)\n",
    "demographic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographic_df.columns =['pct_male', 'pct_foreign', 'pct_female', 'State_Code','Total_Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_male</th>\n",
       "      <th>pct_foreign</th>\n",
       "      <th>pct_female</th>\n",
       "      <th>State_Code</th>\n",
       "      <th>Total_Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>SC</td>\n",
       "      <td>81309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NE</td>\n",
       "      <td>277346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.52</td>\n",
       "      <td>MA</td>\n",
       "      <td>92459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pct_male  pct_foreign  pct_female State_Code  Total_Population\n",
       "2842      0.48         0.06        0.52         SC             81309\n",
       "1876      0.50         0.08        0.50         NE            277346\n",
       "2748      0.48         0.32        0.52         MA             92459"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**3 ) US Airport Data:**  \n",
    "     <li>  filter data without iata_code AND iso_country = 'US' \n",
    "     <li>  count the number of flights in each states \n",
    "     <li>  get the country and state information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# filter iso_counrty <> US and records with no iata_code \n",
    "airport_df  =   airport.loc[(~airport.iata_code.isnull()) & (airport.iso_country=='US'),['iso_country','iso_region']]\\\n",
    "                       .groupby(['iso_region'])['iso_country']\\\n",
    "                       .count().reset_index().rename(columns={\"iso_country\": \"number_of_flights\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# retrieve state information from iso_region column \n",
    "airport_df['country'], airport_df['state'] = airport_df.iso_region.apply(lambda x: x.split('-')[0]), airport_df.iso_region.apply(lambda x: x.split('-')[1])\n",
    "airport_df = airport_df.loc[:,[ 'country', 'state','number_of_flights']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>number_of_flights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>CT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>US</td>\n",
       "      <td>MT</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country state  number_of_flights\n",
       "1       US    AL                 30\n",
       "6       US    CT                  9\n",
       "26      US    MT                 27"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**4 ) US temperature Data:**  \n",
    "     <li>  filter data without in only US and drop the records without temperature information\n",
    "     <li>  get the average monthly temperature by states data\n",
    "     <li>  add a column of abbreviation state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Filtering out data and create a month column \n",
    "temperature = temperatures.loc[(temperatures.Country=='United States') & (~temperatures.AverageTemperature.isnull()),:]\n",
    "temperature['dt'] = pd.to_datetime(temperatue['dt'])\n",
    "temperature['month'] = temperature.dt.apply(lambda x: x.month)\n",
    "\n",
    "# get the average historical monthly temperature \n",
    "temperature_df = temperature.groupby(['Country','State','month'])['AverageTemperature']\\\n",
    "                          .mean().round(2)\\\n",
    "                          .reset_index()\n",
    "temperature_df.State = temperature_df.State.apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Get abbreviations for State\n",
    "temperature_df = temperature_df.merge(i94addr_reference.rename(columns={\"addr\":\"State\",\"code\":'Code'}), how='left', on =\"State\")\n",
    "\n",
    "# Fill out all the States unmatched from i94addr_reference table\n",
    "patch_list = ['DC','GA','NC','ND','SC','SD','WV','WI']\n",
    "for missing_code, code in zip(temperature_df.loc[temperature_df.Code.isnull(),['State','Code']].drop_duplicates().State, patch_list):\n",
    "    temperature_df.loc[temperature_df.State == missing_code,'Code'] = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = temperature_df.loc[:,['Code','month','AverageTemperature'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>month</th>\n",
       "      <th>AverageTemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>IN</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>GA</td>\n",
       "      <td>10</td>\n",
       "      <td>17.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>NC</td>\n",
       "      <td>8</td>\n",
       "      <td>24.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code  month  AverageTemperature\n",
       "168   IN      1               -2.76\n",
       "129   GA     10               17.69\n",
       "403   NC      8               24.46"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    " \n",
    "Here we choose **Star Schema** for this database since we have clear fact and dimension table here.     \n",
    "An ultimate goal is to do analaysis based on immigration data to answer the follow possible questions, for example:   \n",
    "- 1:  Is there a higher possibility for people to land the state which has more foreign people? (higher pct_foregn percentage than other states) \n",
    "- 2:  Does people prefer to go to states with higher temperature in winter and lower temperature in summer? (for vocation) \n",
    "\n",
    "**Fact Table**     \n",
    "    \n",
    " - US_immigration_table \n",
    " >  civid  \n",
    " year, \n",
    " month,  \n",
    " origin_country,   \n",
    " i94port,   \n",
    " city_port_name,   \n",
    " state_code,   \n",
    " dest_state_name   \n",
    " \n",
    "        \n",
    "    \n",
    "**Dimension Tables**   \n",
    "\n",
    " - airport_table   \n",
    " > State,    country,   number_of_flights \n",
    "\n",
    "- demographic_table   \n",
    "> State Code,\n",
    "pct_male, \n",
    "pct_female, \n",
    "pct_foreign, \n",
    "Total Population\n",
    "\n",
    "- temperature_table   \n",
    "> State Code, \n",
    "month, \n",
    "AverageTemperature \n",
    "\n",
    "- i94_table\n",
    " \n",
    " >  civid   year, month,   origin_country,    i94port,    city_port_name,    state_code,    dest_state_name   \n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "- Dimension tables will be created from processed dataset (3 from pandas dataframe + 1 pyspark dataframe).\n",
    "- Fact table will be created by joining the dimensions tables. \n",
    "- Fact table is written as final parquet file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_pyspark_DF =spark.createDataFrame(temperature_df) \n",
    "airport_df_pyspark_DF =spark.createDataFrame(airport_df) \n",
    "demographic_df_pyspark_DF =spark.createDataFrame(demographic_df) \n",
    "\n",
    "\n",
    "# Create Dimension tables\n",
    "demographic_df_pyspark_DF.createOrReplaceTempView(\"demographics\")\n",
    "airport_df_pyspark_DF.createOrReplaceTempView(\"airport\")\n",
    "temperature_pyspark_DF.createOrReplaceTempView(\"temperature\")\n",
    "immigration_df.createOrReplaceTempView(\"i94\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# reset joining time\n",
    "sqlContext.setConf(\"spark.sql.autoBroadcastJoinThreshold\", \"0\")\n",
    "\n",
    "# US immigration monthly view table \n",
    "immigration_stats =spark.sql(\n",
    "\"\"\" \n",
    "SELECT \n",
    "        m.year,\n",
    "        m.month AS immig_month,\n",
    "        m.origin_country AS immig_origin,\n",
    "        m.dest_state_name AS to_immig_state,\n",
    "        COUNT(m.state_code) AS to_immig_state_count,\n",
    "        t.AverageTemperature,\n",
    "        d.pct_foreign,\n",
    "        a.number_of_flights FROM i94 m JOIN temperature t ON m.state_code=t.Code AND m.month=t.month\n",
    "    JOIN demographics d \n",
    "                    ON d.State_Code= t.Code\n",
    "    JOIN airport a \n",
    "                    ON a.state= d.State_Code \n",
    "\n",
    "GROUP BY \n",
    "m.year,m.month, m.origin_country,\n",
    "m.dest_state_name,m.state_code, t.AverageTemperature,a.number_of_flights ,\n",
    "d.pct_foreign\n",
    "\n",
    "ORDER BY m.origin_country,m.state_code\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+------------+--------------+--------------------+------------------+-----------+-----------------+\n",
      "|year|immig_month|immig_origin|to_immig_state|to_immig_state_count|AverageTemperature|pct_foreign|number_of_flights|\n",
      "+----+-----------+------------+--------------+--------------------+------------------+-----------+-----------------+\n",
      "|2016|          6| AFGHANISTAN|      Arkansas|                  10|             24.55|       0.08|               29|\n",
      "|2016|          6| AFGHANISTAN|      Arkansas|                   5|             24.55|       0.15|               29|\n",
      "|2016|          6| AFGHANISTAN|      Arkansas|                   9|             24.55|       0.04|               29|\n",
      "|2016|          6| AFGHANISTAN|      Arkansas|                   5|             24.55|       0.25|               29|\n",
      "|2016|          6| AFGHANISTAN|       Arizona|                   5|             24.08|       0.19|               46|\n",
      "+----+-----------+------------+--------------+--------------------+------------------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigration_stats.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write fact table to parquet\n",
    "immigration_stats.write.parquet(\"immigration_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|       Table|Records|\n",
      "+------------+-------+\n",
      "|         i94|3214208|\n",
      "|demographics|   2891|\n",
      "| temperature|    612|\n",
      "|     Airport|     51|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the record number in Dimension tables \n",
    "Quality_check = spark.sql(\n",
    "\"\"\" Select 'Airport' as Table, count(state) as Records from airport \n",
    "    union \n",
    "    Select 'temperature' as Table, count(Code) as Records from temperature\n",
    "    union \n",
    "    Select 'demographics' as Table, count(State_Code) as Records from demographics\n",
    "    union \n",
    "    Select 'i94' as Table, count(State_Code) as Records from i94\"\"\" )\n",
    "\n",
    "Quality_check.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-------+-----+\n",
      "| year|month|country|state|\n",
      "+-----+-----+-------+-----+\n",
      "|false|false|  false|false|\n",
      "+-----+-----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the nulls\n",
    "immigration_stats.select(isnull('year').alias('year'),\\\n",
    "                 isnull('immig_month').alias('month'),\\\n",
    "                 isnull('immig_origin').alias('country'),\\\n",
    "                 isnull('to_immig_state').alias('state')).dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Dimension Tables** \n",
    "\n",
    "airport  \n",
    "```\n",
    "-  State  (StringType) - two digit Sate code \n",
    "-  country (StringType) - country name \n",
    "-  number_of_flights (LongType) - Aggregated by IATA_code to get number of flights in that Stats\n",
    "```\n",
    "temperature\n",
    "```\n",
    "- Code (StringType)  -two digit Sate code \n",
    "- month (LongType)   - Month presents in number \n",
    "- AverageTemperature (DoubleType) - the average historical temperature of that given month, in Celsius \n",
    "```\n",
    "\n",
    "demographic\n",
    "```\n",
    "- pct_male (DoubleType)  - male percentage of that states \n",
    "- pct_foreign (DoubleType)   - foreign bron people percentage of that states \n",
    "- pct_female (DoubleType) - female percentage of that states \n",
    "- State_Code (StringType) - two digit Sate code   \n",
    "- Total_Population (LongType) - Number of people in that state \n",
    "```\n",
    "\n",
    "i94\n",
    "```\n",
    "- cicid (DoubleType)  - ID number of each individual\n",
    "- year (IntegerType)   - year of immigration\n",
    "- month (IntegerType) - month of immigration\n",
    "- i94port (StringType) - City Port Code where Immigrant entered\n",
    "- city_port_name (StringType) - City Port Code name \n",
    "- state_code (StringType) - two digit Sate code\n",
    "- dest_state_name (StringType) - Detstination State name \n",
    "```\n",
    "\n",
    "**Fact Table**\n",
    "immigration_stats  \n",
    "- year (IntegerType)   - year of immigration\n",
    "- immig_month (IntegerType) - month of immigration\n",
    "- to_immig_state (StringType) - Detstination State name \n",
    "- to_immig_state_count (IntegerType) -Total count of people immigrated per state from immigration table \n",
    "- AverageTemperature (DoubleType) - the average historical temperature of that given month, in Celsius \n",
    "- pct_foreign (DoubleType)   - foreign bron people percentage of that states \n",
    "-  number_of_flights (LongType) - Aggregated by IATA_code to get number of flights in that Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Summary**\n",
    "<li>  This project used Pandas as data wrangling/cleaning tool since its functionality and ease of use. Also, Apache Spark was used to do the Extract, transform and load tool since this dataset is relatively small.  \n",
    "<li>  This data should be updated on a monthly basis since the Fact table (immigration stats) present the monthly overview of aggregated information by temperature, people into US etc. A monthly update will ensure the users to get new data in timely basis and also will ease the loading traffic. \n",
    "\n",
    "**Changes by Scenario** \n",
    "<li>  If the data increased by 100x, i'll take the advantage of the Hadoop to get more node boosting the performance. \n",
    "<li>  If the data must be updated on a daily basis by 7am every day, i'll use the Airflow and set a day schedule_interval through the Airlow service. a\n",
    "<li>  If the data needs to be accessed by 100+ people, I'll get a web app running on AWS based and also will save my data in S3 with replication.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
